    # This is an example config file that can be used to initiate a hyperparameter sweep
    # using the Weights and Biases experiment tracking platform
    # See: https://docs.wandb.ai/guides/sweeps
# This is an example config file that can be used to initiate a hyperparameter sweep
# using the Weights and Biases experiment tracking platform
# See: https://docs.wandb.ai/guides/sweeps
project: "LetsGoDRL"
name: "MULTIBANDRSA"
program: train.py
method: bayes
metric:
  name: service_blocking_probability
  goal: minimize
parameters:
  GAMMA:
    min: 0.85
    max: 0.98
  GAE_LAMBDA:
    min: 0.8
    max: 0.95
  ROLLOUT_LENGTH:
    values:
      - 10
      - 20
      - 50
  LR:
    min: 5e-5
    max: 5e-3
  UPDATE_EPOCHS:
    values:
      - 5
      - 10
      - 15
  WARMUP_PEAK_MULTIPLIER:
    values:
      - 2
      - 3
  gnn_latent:
    values:
      - 128
  gnn_mlp_layers:
    values:
      - 2
      - 3
      - 4
  message_passing_steps:
    values:
      - 3
      - 4
  SCHEDULE_MUTLIPLIER:
    values:
      - 5
      - 10
      - 15
  NUM_ENVS:
    values:
      - 10
      - 20
      - 40
  DOWNSAMPLE_FACTOR:
    values:
      - 10
      - 20
      - 50
command:
  - ${env}
  - python3
  - ${program}
  - "--env_type"
  - "multibandrsa"
  - "--end_first_blocking"
  - "--incremental_loading"
  - "--load"
  - 100
  - "--k"
  - 5
  - "--topology_name"
  - "nsfnet_deeprmsa_undirected"
  - "--link_resources"
  - 98
  - "--values_bw"
  - 400
  - "--slot_size"
  - 100
  - "--interband_gap_start"
  - 4800
  - "--interband_gap_width"
  - 200
  - "--TOTAL_TIMESTEPS"
  - 50000
  - "--ENV_WARMUP_STEPS"
  - 0
  - "--ACTION_MASKING"
  - "--PLOTTING"
  - "--USE_GNN"
  - "--LR_SCHEDULE"
  - "warmup_cosine"
  - ${args}